{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# My hangman file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import math\n",
    "import requests\n",
    "import random\n",
    "import string\n",
    "import secrets\n",
    "import time\n",
    "import re\n",
    "import collections\n",
    "from nltk import ngrams, FreqDist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = open(\"words_250000_train.txt\",\"r\")\n",
    "full_dict = tf.read().splitlines()\n",
    "tf.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'magyarization'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.choice(full_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dict_common_letter_sorted = collections.Counter(\"\".join(full_dict)).most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('e', 233745)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_dict_common_letter_sorted[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.361986056547824"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.log(233745)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, the main things I am revising are the n-gram matching and the evaluate guesses. What do they have to do?\n",
    "-Ok, I match the n-grams in a different way than other people do it, but I think my way is better.\n",
    "-I need to pad out the left and right for the n-gram for the generated word. The padding is to match for n-grams at the beginning and end I guess\n",
    "    -maybe I shouldnt do this...\n",
    "    -However, I have to discount stuff that is like (None a) or (a None) because those will cause issues with the \n",
    "-matching only can reccommend ONE letter. the way it is done in the other programs is forcing it into cases... but I can do it a different way.\n",
    "\n",
    "I am going to break the functions down here, fix them, and paste them back...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dictionary = full_dict\n",
    "\n",
    "#set up n-grams for current dictionary\n",
    "grams2 = []\n",
    "grams3 = []\n",
    "grams4 = []\n",
    "grams5 = []\n",
    "for word in full_dictionary:\n",
    "    #is the word clean? It should be...\n",
    "    #when I loaded the data it's fine...\n",
    "    #the API has be a bit nervous so lets just put this here\n",
    "    word = word.replace(\" \", \"\") #remove any padding that may mess with this\n",
    "\n",
    "    grams2.extend(list(ngrams(word, 2))) #if I pad left and match NONES with the length 2 n-grams, the program will start guessing first and last letters first...\n",
    "    grams3.extend(list(ngrams(word, 3, pad_left = True, pad_right = True)))\n",
    "    grams4.extend(list(ngrams(word, 4, pad_left = True, pad_right = True)))\n",
    "    grams5.extend(list(ngrams(word, 5, pad_left = True, pad_right = True)))\n",
    "\n",
    "#Ok, so now need the frequency distributions for these\n",
    "freq_dist_2 = FreqDist(grams2)\n",
    "freq_dist_3 = FreqDist(grams3)\n",
    "freq_dist_4 = FreqDist(grams4)\n",
    "freq_dist_5 = FreqDist(grams5)\n",
    "\n",
    "#need to actually extract the data from these distributions to use it\n",
    "freq_dist_2 = [(item, freq_dist_2.get(item)) for item in freq_dist_2]\n",
    "freq_dist_3 = [(item, freq_dist_3.get(item)) for item in freq_dist_3]\n",
    "freq_dist_4 = [(item, freq_dist_4.get(item)) for item in freq_dist_4]\n",
    "freq_dist_5 = [(item, freq_dist_5.get(item)) for item in freq_dist_5]\n",
    "\n",
    "words_by_length = {}\n",
    "min_word_length = 3 #shortest in the full_dict at least\n",
    "max_word_length = 40 #I guess this is pretty arbitrary\n",
    "\n",
    "for i in range(min_word_length, max_word_length):\n",
    "    words_by_length.update({i : []})\n",
    "\n",
    "#I do it in this kinda roundabout way because maybe there are words of 25 and 28 but no 27 or whatever\n",
    "#for word in self.full_dictionary:\n",
    "#    self.full_dictionary[len(word)].append(word)\n",
    "    \n",
    "\n",
    "#manually input a word and guess word...\n",
    "correct_word = \"apple\"\n",
    "word = \"_pp_e\"\n",
    "guess_list = [\"s\", \"p\", \"t\", \"e\"]\n",
    "#failed_letters = [\"s\", \"t\"]\n",
    "\n",
    "\n",
    "#def update_grams(self, word, guess_list):\n",
    "        #update ngrams to remove items associated with incorrect letters\n",
    "temp_word = word.replace(\"_\", \"\")\n",
    "incorrect_letters = set(guess_list) - set(temp_word)\n",
    "freq_dist_2 = [(item[0], item[1]) for item in freq_dist_2 if set(item[0]).isdisjoint(set(incorrect_letters))]\n",
    "freq_dist_3 = [(item[0], item[1]) for item in freq_dist_3 if set(item[0]).isdisjoint(set(incorrect_letters))]\n",
    "freq_dist_4 = [(item[0], item[1]) for item in freq_dist_4 if set(item[0]).isdisjoint(set(incorrect_letters))]\n",
    "freq_dist_5 = [(item[0], item[1]) for item in freq_dist_5 if set(item[0]).isdisjoint(set(incorrect_letters))]\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_potential_guesses(freq_N, input_word, guess_list):\n",
    "        #This takes as input a freq dist for n-grams and a word\n",
    "        #it outputs all the n-grams from freq dist that match along with the \n",
    "        potential_guesses = []\n",
    "        filtered_dist = []\n",
    "        if(freq_N == []):\n",
    "            dimension = 0\n",
    "        else:\n",
    "            dimension = len(freq_N[0][0])\n",
    "        word_ngrams = list(ngrams(input_word, dimension, pad_left = True, pad_right = True))\n",
    "        #print(dimension)\n",
    "        #There is an issue though, too much padding, so I will prune the word ngrams to prevent weird overmatching of NONEs\n",
    "        #print(item[0] for item in word_ngrams)\n",
    "        #print(word_ngrams)\n",
    "        word_ngrams = [item for item in word_ngrams if item.count(None) < 2]\n",
    "\n",
    "        for fe in freq_N:\n",
    "            #Ok..... so here is the idea...\n",
    "            #if the ngram in fe matches, then it must be a match \n",
    "            #to one of the n-gons of the target word with wildcards\n",
    "            fe_gram = fe[0]\n",
    "            occurrences = fe[1]\n",
    "            \n",
    "            #now, try to match it to one of the n-grams of the word...\n",
    "            matched_letters_count = 0 #you must match at least one letter to be considered\n",
    "\n",
    "            #how about this, I will potentially return guesses that are already in the guess_list\n",
    "            #and then filter them out in the next program when I go to evaluate the guesses.\n",
    "            #maybe also worry about the vowel thing there instead of here.\n",
    "\n",
    "            remove_set = set(guess_list)\n",
    "            remove_set.add(None)\n",
    "            \n",
    "            #print(\"I am inside the if statement\")\n",
    "            for word_gram in word_ngrams:\n",
    "                matched_letters_count = 0\n",
    "                for i in range(dimension):\n",
    "                    if(word_gram[i] != \"_\"): #there is a letter here, does the fe match?\n",
    "                        if(fe_gram[i] == word_gram[i]):\n",
    "                            matched_letters_count += 1\n",
    "                        else:\n",
    "                            #this happens if we have a direct contradiction, immediately reject this\n",
    "                            matched_letters_count = 0\n",
    "                            break\n",
    "                    #we don't have to check what the corresponding letter is if word_gram[i] is blank!\n",
    "                if(matched_letters_count == dimension - 1): #there should be n-1 matches and 1 guess\n",
    "                    potential_guesses.append((set(fe_gram) - remove_set, dimension,occurrences))\n",
    "                    #this is just for testing below vvvvvvvvv\n",
    "                    #potential_guesses.append((set(fe_gram) - remove_set, fe_gram, dimension,occurrences))\n",
    "\n",
    "                    #filtered_dist.append(fe)\n",
    "                    #print(set(fe_gram).issubset(guess_list))\n",
    "            \n",
    "        return potential_guesses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[({'r'}, 2, 24800),\n",
       " ({'l'}, 2, 22135),\n",
       " ({'n'}, 2, 19584),\n",
       " ({'d'}, 2, 13954),\n",
       " ({'h'}, 2, 11707),\n",
       " ({'m'}, 2, 11077),\n",
       " ({'v'}, 2, 10593),\n",
       " (set(), 2, 10209),\n",
       " (set(), 2, 10209),\n",
       " ({'c'}, 2, 9023),\n",
       " ({'h'}, 2, 8865),\n",
       " ({'r'}, 2, 8590),\n",
       " ({'i'}, 2, 8301),\n",
       " ({'o'}, 2, 8175),\n",
       " ({'g'}, 2, 7326),\n",
       " ({'a'}, 2, 7313),\n",
       " ({'o'}, 2, 7255),\n",
       " ({'i'}, 2, 6063),\n",
       " ({'a'}, 2, 6038),\n",
       " ({'b'}, 2, 5974),\n",
       " (set(), 2, 5426),\n",
       " ({'k'}, 2, 5188),\n",
       " (set(), 2, 5034),\n",
       " ({'l'}, 2, 4323),\n",
       " ({'i'}, 2, 4121),\n",
       " ({'m'}, 2, 3951),\n",
       " ({'z'}, 2, 3531),\n",
       " ({'a'}, 2, 3350),\n",
       " ({'f'}, 2, 3328),\n",
       " ({'w'}, 2, 3228),\n",
       " ({'u'}, 2, 2942),\n",
       " (set(), 2, 2260),\n",
       " (set(), 2, 2260),\n",
       " ({'u'}, 2, 2259),\n",
       " ({'u'}, 2, 2223),\n",
       " ({'y'}, 2, 2029),\n",
       " ({'r'}, 2, 2021),\n",
       " ({'o'}, 2, 1715),\n",
       " ({'n'}, 2, 1403),\n",
       " ({'y'}, 2, 1380),\n",
       " ({'y'}, 2, 970),\n",
       " ({'l'}, 2, 950),\n",
       " ({'j'}, 2, 735),\n",
       " ({'x'}, 2, 638),\n",
       " ({'x'}, 2, 540),\n",
       " ({'n'}, 2, 304),\n",
       " ({'d'}, 2, 190),\n",
       " ({'b'}, 2, 145),\n",
       " ({'m'}, 2, 141),\n",
       " ({'h'}, 2, 140),\n",
       " ({'w'}, 2, 124),\n",
       " ({'f'}, 2, 123),\n",
       " ({'b'}, 2, 122),\n",
       " ({'c'}, 2, 122),\n",
       " ({'f'}, 2, 116),\n",
       " ({'k'}, 2, 111),\n",
       " ({'d'}, 2, 84),\n",
       " ({'g'}, 2, 81),\n",
       " ({'w'}, 2, 73),\n",
       " ({'g'}, 2, 56),\n",
       " ({'c'}, 2, 51),\n",
       " ({'k'}, 2, 45),\n",
       " ({'v'}, 2, 17),\n",
       " ({'j'}, 2, 14),\n",
       " ({'z'}, 2, 12),\n",
       " ({'v'}, 2, 7),\n",
       " ({'q'}, 2, 5),\n",
       " ({'j'}, 2, 3),\n",
       " ({'x'}, 2, 2),\n",
       " ({'z'}, 2, 1),\n",
       " ({'q'}, 2, 1),\n",
       " ({'q'}, 2, 1)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_potential_guesses(freq_dist_2, word, guess_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are issues with the padding... I need to prune everything that has at least 2 NONEs. That includes the `freq_n` and the ngrams of the word...\n",
    "Maybe I just need to prune the ones from the word?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[({'a'}, 4, 275),\n",
       " ({'l'}, 4, 135),\n",
       " ({'l'}, 4, 122),\n",
       " ({'r'}, 4, 119),\n",
       " ({'i'}, 4, 66),\n",
       " ({'o'}, 4, 56),\n",
       " ({'i'}, 4, 42),\n",
       " ({'u'}, 4, 32),\n",
       " ({'h'}, 4, 26),\n",
       " (set(), 4, 26),\n",
       " (set(), 4, 25),\n",
       " (set(), 4, 10),\n",
       " (set(), 4, 5),\n",
       " ({'n'}, 4, 4),\n",
       " ({'a'}, 4, 4),\n",
       " ({'r'}, 4, 4),\n",
       " (set(), 4, 4),\n",
       " ({'o'}, 4, 3),\n",
       " ({'u'}, 4, 3),\n",
       " ({'a'}, 4, 2),\n",
       " ({'n'}, 4, 2),\n",
       " ({'c'}, 4, 2),\n",
       " ({'d'}, 4, 1),\n",
       " ({'l'}, 4, 1),\n",
       " ({'m'}, 4, 1),\n",
       " ({'n'}, 4, 1),\n",
       " ({'d'}, 4, 1),\n",
       " (set(), 4, 1),\n",
       " ({'y'}, 4, 1),\n",
       " ({'h'}, 4, 1),\n",
       " ({'j'}, 4, 1),\n",
       " ({'k'}, 4, 1)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_potential_guesses(freq_dist_4, word, guess_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[({'l'}, 5, 37), ({'i'}, 5, 13), (set(), 5, 2), ({'a'}, 5, 1)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_potential_guesses(freq_dist_5, word, guess_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_2_guesses = find_potential_guesses(freq_dist_2, word, guess_list)\n",
    "freq_3_guesses = find_potential_guesses(freq_dist_3, word, guess_list)\n",
    "freq_4_guesses = find_potential_guesses(freq_dist_4, word, guess_list)\n",
    "freq_5_guesses = find_potential_guesses(freq_dist_5, word, guess_list)\n",
    "all_guesses = freq_2_guesses + freq_3_guesses + freq_4_guesses + freq_5_guesses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[({'r'}, 2, 24800), ({'l'}, 2, 22135), ({'n'}, 2, 19584), ({'d'}, 2, 13954), ({'h'}, 2, 11707), ({'m'}, 2, 11077), ({'v'}, 2, 10593), (set(), 2, 10209), (set(), 2, 10209), ({'c'}, 2, 9023)]\n"
     ]
    }
   ],
   "source": [
    "print(all_guesses[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[({'l'}, 5, 37), ({'i'}, 5, 13), ({'a'}, 5, 1), ({'a'}, 4, 275), ({'l'}, 4, 135), ({'l'}, 4, 122), ({'r'}, 4, 119), ({'i'}, 4, 66), ({'o'}, 4, 56), ({'i'}, 4, 42)]\n"
     ]
    }
   ],
   "source": [
    "filtered_guesses = [item for item in all_guesses if item[0] != set()] #this filters out all the guesses with no letters in them\n",
    "sorted_guesses = sorted(filtered_guesses, key = lambda tup: tup[1], reverse = True)\n",
    "print(sorted_guesses[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_potential_guesses(potential_guesses):\n",
    "        #each potential guess is in the form:\n",
    "        #({letters}, dimension from ngram, matched letters count, occurrences of pattern in dict)\n",
    "\n",
    "        #So, which do we pick:\n",
    "        #prioritize ngram length first\n",
    "        #then pick based on most frequent letter\n",
    "        #I guess how many letters match isnt as important...\n",
    "        #I have read that vowel ratio may make a difference... maybe implement later\n",
    "\n",
    "        sorted_guesses = sorted(potential_guesses, key = lambda tup: tup[1], reverse = True)\n",
    "        if(sorted_guesses != []):\n",
    "            max_dim = sorted_guesses[0][1]\n",
    "            #print(max_dim)\n",
    "            max_dim_guesses = [x for x in sorted_guesses if x[1] == max_dim]\n",
    "            max_dim_guesses.sort(key = lambda tup: tup[2], reverse = True)\n",
    "\n",
    "            #print(max_dim_guesses[0])\n",
    "            max_dim_guesses[0][0]\n",
    "            max_guess = max_dim_guesses[0]\n",
    "            #print(max_guess)\n",
    "            max_guess = list(max_guess)[0] #this is to get the actual string instead of a set\n",
    "            if len(max_guess) > 0:\n",
    "                max_guess = list(max_guess)[0]\n",
    "            \n",
    "            \n",
    "            return max_guess #this is a set in general\n",
    "        else:\n",
    "            return \"!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'l'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_potential_guesses(all_guesses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok... now just need a program to sort through all of the different n-grams and pick the best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import ngrams, FreqDist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = \"_pp_\"\n",
    "test.count(\"_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "#word = \"_pp_e\"\n",
    "#word2 = \"app__\"\n",
    "#word = \"agrumen_a_ive\"\n",
    "word = \"________\"\n",
    "\n",
    "#first pad beginning and end of word with something, will replace with None later\n",
    "substr_lists = []\n",
    "word = \".\" + word + \".\" # I think this is ok\n",
    "#word = temp_word\n",
    "for i,char in enumerate(word):\n",
    "    if char == \"_\": #found a blank\n",
    "        start, end = i, i\n",
    "        #get longest substring containing the blank\n",
    "        while start > 0 and word[start-1] != \"_\":\n",
    "            start-=1\n",
    "        while end < len(word) - 1 and word[end+1] != \"_\":\n",
    "            end += 1\n",
    "        #now, turn substring into something to match an n-gram\n",
    "        substring = word[start:end + 1]\n",
    "        ssList = list(substring)\n",
    "        if ssList[0] == \".\": ssList[0] = None\n",
    "        if ssList[-1] == \".\": ssList[-1] = None\n",
    "        #print ssList)\n",
    "        #what if substr is longer length than 5?\n",
    "        #NOTE, IF I USE NGRAMS LONGER THAN 5 NEED TO UPDATE THIS!\n",
    "        if(len(ssList) > 5):\n",
    "            grams = ngrams(ssList, 5)\n",
    "            for g in grams:\n",
    "                #print(g)\n",
    "                if(g.count(\"_\") == 1):\n",
    "                    substr_lists.append(g)\n",
    "            #print(grams)\n",
    "        elif(set(ssList) - set({None, \"_\"}) != set()):\n",
    "            substr_lists.append(ssList)\n",
    "        \n",
    "print(substr_lists)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyHangman(object):\n",
    "    def __init__(self, access_token=None, session=None, timeout=None):\n",
    "        self.guessed_letters = []\n",
    "        #should include a self word and self correct word\n",
    "        self.word = \"\"\n",
    "        self.correct_word = \"\"\n",
    "        full_dictionary_location = \"words_250000_train.txt\"\n",
    "        self.full_dictionary = self.build_dictionary(full_dictionary_location)        \n",
    "        self.full_dictionary_common_letter_sorted = collections.Counter(\"\".join(self.full_dictionary)).most_common()\n",
    "        self.current_dictionary = []\n",
    "        self.alphabet = list(string.ascii_lowercase)\n",
    "        self.vowels = list([\"a\", \"e\", \"i\", \"o\", \"u\"])\n",
    "        self.guess_list = []\n",
    "        self.has_won = False\n",
    "        self.init_grams()\n",
    "        #self.init_grams()\n",
    "\n",
    "    def init_grams(self):\n",
    "        #set up n-grams for current dictionary\n",
    "        grams2 = []\n",
    "        grams3 = []\n",
    "        grams4 = []\n",
    "        grams5 = []\n",
    "        for word in self.full_dictionary:\n",
    "            #is the word clean? It should be...\n",
    "            #when I loaded the data it's fine...\n",
    "            #the API has be a bit nervous so lets just put this here\n",
    "            word = word.replace(\" \", \"\") #remove any padding that may mess with this\n",
    "\n",
    "            grams2.extend(list(ngrams(word, 2)))# padding on 2 messes up the guesses.\n",
    "            grams3.extend(list(ngrams(word, 3, pad_left = True, pad_right = True)))\n",
    "            grams4.extend(list(ngrams(word, 4, pad_left = True, pad_right = True)))\n",
    "            grams5.extend(list(ngrams(word, 5, pad_left = True, pad_right = True)))\n",
    "        \n",
    "        #Ok, so now need the frequency distributions for these\n",
    "        freq_dist_2 = FreqDist(grams2)\n",
    "        freq_dist_3 = FreqDist(grams3)\n",
    "        freq_dist_4 = FreqDist(grams4)\n",
    "        freq_dist_5 = FreqDist(grams5)\n",
    "\n",
    "        #need to actually extract the data from these distributions to use it\n",
    "        self.freq_dist_2 = [(item, freq_dist_2.get(item)) for item in freq_dist_2]\n",
    "        self.freq_dist_3 = [(item, freq_dist_3.get(item)) for item in freq_dist_3]\n",
    "        self.freq_dist_4 = [(item, freq_dist_4.get(item)) for item in freq_dist_4]\n",
    "        self.freq_dist_5 = [(item, freq_dist_5.get(item)) for item in freq_dist_5]\n",
    "\n",
    "        self.words_by_length = {}\n",
    "        min_word_length = 3 #shortest in the full_dict at least\n",
    "        max_word_length = 40 #I guess this is pretty arbitrary\n",
    "\n",
    "        for i in range(min_word_length, max_word_length):\n",
    "            self.words_by_length.update({i : []})\n",
    "\n",
    "        #I do it in this kinda roundabout way because maybe there are words of 25 and 28 but no 27 or whatever\n",
    "        #for word in self.full_dictionary:\n",
    "        #    self.full_dictionary[len(word)].append(word)\n",
    "        \n",
    "            \n",
    "        \n",
    "    def generate_correct_word(self):\n",
    "        self.correct_word = random.choice(self.full_dictionary)\n",
    "\n",
    "\n",
    "\n",
    "    def find_potential_guesses(self, freq_N_array, input_word, guess_list):\n",
    "        #This takes as input an array containing each freq_N\n",
    "        #it outputs all the n-grams from freq dist that match and stuff that will be used to calc the weight\n",
    "        potential_guesses = []\n",
    "        filtered_dist = []\n",
    "        #if(freq_N == []):\n",
    "        #    return potential_guesses\n",
    "        #else:\n",
    "        #    dimension = len(freq_N[0][0])\n",
    "\n",
    "        remove_set = set(guess_list)\n",
    "        remove_set.add(None)\n",
    "\n",
    "        #Ok, so we need to get the longest substrings in the word that contain ONE blank space.\n",
    "        #first pad beginning and end of word with something, will replace with None later\n",
    "        substr_lists = []\n",
    "        input_word = \".\" + input_word + \".\" # I think this is ok\n",
    "        #word = temp_word\n",
    "        #print(input_word)\n",
    "        for i,char in enumerate(input_word):\n",
    "            if char == \"_\": #found a blank\n",
    "                start, end = i, i\n",
    "                #print(i)\n",
    "                #get longest substring containing the blank\n",
    "                while start > 0 and input_word[start-1] != \"_\":\n",
    "                    start-=1\n",
    "                    #print(start)\n",
    "                while end < len(input_word) - 1 and input_word[end+1] != \"_\":\n",
    "                    end += 1\n",
    "                    #print(end)\n",
    "                #now, turn substring into something to match an n-gram\n",
    "                substring = input_word[start:end + 1]\n",
    "                ssList = list(substring)\n",
    "                if ssList[0] == \".\": ssList[0] = None\n",
    "                if ssList[-1] == \".\": ssList[-1] = None\n",
    "                #print ssList)\n",
    "                #what if substr is longer length than 5?\n",
    "                #NOTE, IF I USE NGRAMS LONGER THAN 5 NEED TO UPDATE THIS!\n",
    "                if(len(ssList) > 5):\n",
    "                    grams = ngrams(ssList, 5)\n",
    "                    for g in grams:\n",
    "                        #print(g)\n",
    "                        if(g.count(\"_\") == 1):\n",
    "                            substr_lists.append(g)\n",
    "                    #print(grams)\n",
    "                elif(set(ssList) - set({None, \"_\"}) != set()): #There must be something in the set other than underscores and nones\n",
    "                    substr_lists.append(ssList)\n",
    "        for substr in substr_lists: \n",
    "            dimension = len(substr)\n",
    "            freq_N = freq_N_array[dimension-2]\n",
    "            for fe in freq_N:\n",
    "                fe_gram = fe[0]\n",
    "                occurrences = fe[1]\n",
    "\n",
    "                matched_letters_count = 0\n",
    "                for i in range(dimension):\n",
    "                    if(substr[i] != \"_\"): #there is a letter here, does the fe match?\n",
    "                            if(fe_gram[i] == substr[i]):\n",
    "                                matched_letters_count += 1\n",
    "                            else:\n",
    "                                matched_letters_count -=1\n",
    "                                break\n",
    "                        #we don't have to check what the corresponding letter is if word_gram[i] is blank!\n",
    "                    if(matched_letters_count == dimension - 1 and len((set(fe_gram) - remove_set)) == 1): #there should be n-1 matches and 1 guess\n",
    "                        potential_guesses.append((set(fe_gram) - remove_set, dimension, occurrences))\n",
    "            \n",
    "        return potential_guesses\n",
    "        \n",
    "\n",
    "    def evaluate_potential_guesses(self, potential_guesses):\n",
    "        print(potential_guesses)\n",
    "        if(potential_guesses == []):\n",
    "            return \"!\" # no n-gram fits\n",
    "        # Initialize dictionary to keep scores for each guess\n",
    "        scores = {}\n",
    "\n",
    "        # Weighting factors, these are the main thing to tweak...\n",
    "        weight_frequency = 0.25\n",
    "        weight_length = 2.0  # Giving more weight to the length of the n-gram\n",
    "\n",
    "        for guess, length, occurrences in potential_guesses:\n",
    "            guess_letter = list(guess)[0]  # Extract the letter from the set\n",
    "\n",
    "            # Calculate the score for this guess\n",
    "            score = (np.log(occurrences) * weight_frequency) + (length * weight_length)\n",
    "\n",
    "            # Add or update the score for this letter in the scores dictionary\n",
    "            if guess_letter in scores:\n",
    "                scores[guess_letter] += score\n",
    "            else:\n",
    "                scores[guess_letter] = score\n",
    "\n",
    "        # Determine the best guess by finding the maximum score\n",
    "        #print(scores)\n",
    "        best_guess = max(scores, key=scores.get)\n",
    "        return best_guess\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    def update_grams(self, freq_dist_list ,word, guess_list):\n",
    "        #freq_grams is in the form [freq_dist_2, freq_dist_3, freq_dist_4, freq_dist_5]\n",
    "\n",
    "        #update ngrams to remove items associated with incorrect letters\n",
    "        word = word.replace(\"_\", \"\")\n",
    "        incorrect_letters = set(guess_list) - set(word)\n",
    "        for freq_dist in freq_dist_list:\n",
    "            freq_dist = [(item[0], item[1]) for item in freq_dist if set(item[0]).isdisjoint(set(incorrect_letters))]\n",
    "        #freq_dist_2 = [(item[0], item[1]) for item in freq_dist_2 if set(item[0]).isdisjoint(set(incorrect_letters))]\n",
    "        #freq_dist_3 = [(item[0], item[1]) for item in freq_dist_3 if set(item[0]).isdisjoint(set(incorrect_letters))]\n",
    "        #freq_dist_4 = [(item[0], item[1]) for item in freq_dist_4 if set(item[0]).isdisjoint(set(incorrect_letters))]\n",
    "        #freq_dist_5 = [(item[0], item[1]) for item in freq_dist_5 if set(item[0]).isdisjoint(set(incorrect_letters))]\n",
    "        return freq_dist_list\n",
    "\n",
    "\n",
    "\n",
    "    def guess(self, word, freq_dist_list): # word input example: \"_ p p _ e \"\n",
    "        ###############################################\n",
    "        # Replace with your own \"guess\" function here #\n",
    "        ###############################################\n",
    "\n",
    "        # clean the word so that we strip away the space characters\n",
    "        # replace \"_\" with \".\" as \".\" indicates any character in regular expressions\n",
    "        # The extra space characters must be coming from the website...\n",
    "        clean_word = word.replace(\" \", \"\") #I am putting this here in case I forget later to remove the space stuff when I paste this into the solution\n",
    "        #clean_word = word.replace(\"_\",\".\") #I am using underscores\n",
    "\n",
    "        # find length of passed word\n",
    "        len_word = len(clean_word)\n",
    "        \n",
    "        # grab current dictionary of possible words from self object, initialize new possible words dictionary to empty\n",
    "        current_dictionary = self.current_dictionary\n",
    "        new_dictionary = []\n",
    "        #print(current_dictionary[0])\n",
    "        \n",
    "        # iterate through all of the words in the old plausible dictionary\n",
    "        reMatchWord = clean_word.replace(\"_\",\".\")\n",
    "        for dict_word in current_dictionary:\n",
    "            # continue if the word is not of the appropriate length\n",
    "            if len(dict_word) != len_word:\n",
    "                continue\n",
    "                \n",
    "            # if dictionary word is a possible match then add it to the current dictionary\n",
    "            if re.match(reMatchWord, dict_word):\n",
    "                new_dictionary.append(dict_word)\n",
    "        \n",
    "        # overwrite old possible words dictionary with updated version\n",
    "        self.current_dictionary = new_dictionary\n",
    "        \n",
    "        \n",
    "        # count occurrence of all characters in possible word matches\n",
    "        full_dict_string = \"\".join(new_dictionary)\n",
    "        \n",
    "        c = collections.Counter(full_dict_string)\n",
    "        sorted_letter_count = c.most_common()\n",
    "        #print(sorted_letter_count)                \n",
    "        \n",
    "        guess_letter = '!'\n",
    "\n",
    "        all_guesses = self.find_potential_guesses(freq_dist_list, word, self.guessed_letters)\n",
    "        ngram_guess = self.evaluate_potential_guesses(all_guesses)\n",
    "        \n",
    "        \n",
    "        # return most frequently occurring letter in all possible words that hasn't been guessed yet\n",
    "        #print(sorted_letter_count)\n",
    "        for letter,instance_count in sorted_letter_count:\n",
    "            if letter not in self.guessed_letters:\n",
    "                most_common_guess = letter\n",
    "                #print(most_common_guess)\n",
    "                break\n",
    "        \n",
    "        \n",
    "        if(ngram_guess != \"!\"):\n",
    "            return ngram_guess\n",
    "        else:\n",
    "            return most_common_guess\n",
    "\n",
    "\n",
    "    ##########################################################\n",
    "    # You'll likely not need to modify any of the code below #\n",
    "    ##########################################################\n",
    "    \n",
    "    def build_dictionary(self, dictionary_file_location):\n",
    "        text_file = open(dictionary_file_location,\"r\")\n",
    "        full_dictionary = text_file.read().splitlines()\n",
    "        text_file.close()\n",
    "        return full_dictionary\n",
    "\n",
    "    #what do I need to replace the responses?\n",
    "    #get a word\n",
    "    #get remaining tries\n",
    "    #print number of tries remaining\n",
    "    #go through the process of resolving a guess\n",
    "    #\n",
    "\n",
    "    def handle_guess(self, guessLetter, currentWord, ans):\n",
    "        #I have to convert the strings to lists, find indices of the letter (if present) and then smush the lists back into strings and spit it out\n",
    "        indices = [i for i, x in enumerate(list(ans)) if x == guessLetter]\n",
    "        wordList = list(currentWord)\n",
    "        for i in indices:\n",
    "            wordList[i] = guessLetter #now I replace the occurrences of the letter\n",
    "        word = \"\".join(wordList)\n",
    "        return word\n",
    "\n",
    "    def get_winstate(self):\n",
    "        return self.has_won\n",
    "        \n",
    "                \n",
    "    def start_game(self, practice=True, verbose=True):\n",
    "        # reset guessed letters to empty set and current plausible dictionary to the full dictionary\n",
    "        self.guessed_letters = []\n",
    "        self.current_dictionary = self.full_dictionary\n",
    "        #self.init_grams()\n",
    "        freq_dist_list = [self.freq_dist_2, self.freq_dist_3, self.freq_dist_4, self.freq_dist_5]\n",
    "        self.has_won = False\n",
    "        #pick a word from the dictionary at random.\n",
    "        #correctWord = random.choice(self.full_dictionary) #this is the initial word, but need to update it based on guesses\n",
    "        self.generate_correct_word()\n",
    "        word = \"_\" * len(self.correct_word) #I should make this a member of self right?\n",
    "\n",
    "        tries_remains = 6 #I think this needs to just be a magic number?\n",
    "        if verbose:\n",
    "            print(\"Successfully start a new game! # of tries remaining: {0}. Word: {1}.\".format(tries_remains, word))\n",
    "        while tries_remains >0:\n",
    "            #tries_remains -=1 tries remains decreases after WRONG answer\n",
    "\n",
    "            #get guessed letter\n",
    "            guess_letter = self.guess(word, freq_dist_list)\n",
    "\n",
    "            #append guessed letter to guessed letters field in hangman object\n",
    "            self.guessed_letters.append(guess_letter)\n",
    "\n",
    "            freq_dist_list = self.update_grams(freq_dist_list, word, self.guess_list)\n",
    "            if verbose:\n",
    "                print(\"Guessing letter: {0}\".format(guess_letter))\n",
    "\n",
    "            #apply guessed letter to the word\n",
    "            new_word = self.handle_guess(guess_letter, word, self.correct_word) \n",
    "\n",
    "            #check if we have the word\n",
    "            if new_word == self.correct_word:\n",
    "                word = new_word\n",
    "                if verbose:\n",
    "                    print(\"Success! the word was: %s\" % word)\n",
    "                self.has_won = True\n",
    "                break\n",
    "            \n",
    "            if new_word == word:\n",
    "                #this means that we did not get a correct guess\n",
    "                #decrease number of tries\n",
    "                if verbose:\n",
    "                    print(\"Incorrect guess {0}, # of tries remaining: {1}. Word: {2}.\".format(guess_letter,tries_remains, word))\n",
    "                tries_remains -=1\n",
    "            else:\n",
    "                #We have a correct letter guessed, but not the complete word\n",
    "                #don't decrement tries_remains\n",
    "                word = new_word\n",
    "                if verbose:\n",
    "                    print(\"Got a Letter, {0}, # of tries remaining: {1}. Word: {2}.\".format(guess_letter,tries_remains, word))\n",
    "        if tries_remains == 0:\n",
    "            if verbose:\n",
    "                print(\"You Lose, the answer was: %s\" % self.correct_word)\n",
    "                \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "game = MyHangman()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully start a new game! # of tries remaining: 6. Word: _____.\n",
      "[]\n",
      "Guessing letter: a\n",
      "Incorrect guess a, # of tries remaining: 6. Word: _____.\n",
      "[]\n",
      "Guessing letter: e\n",
      "Incorrect guess e, # of tries remaining: 5. Word: _____.\n",
      "[]\n",
      "Guessing letter: s\n",
      "Incorrect guess s, # of tries remaining: 4. Word: _____.\n",
      "[]\n",
      "Guessing letter: o\n",
      "Got a Letter, o, # of tries remaining: 3. Word: ____o.\n",
      "[({'t'}, 3, 355), ({'r'}, 3, 334), ({'n'}, 3, 289), ({'d'}, 3, 265), ({'l'}, 3, 253), ({'i'}, 3, 249), ({'c'}, 3, 227), ({'g'}, 3, 181), ({'m'}, 3, 109), ({'h'}, 3, 107), ({'b'}, 3, 82), ({'k'}, 3, 70), ({'p'}, 3, 49), ({'z'}, 3, 47), ({'v'}, 3, 47), ({'y'}, 3, 29), ({'f'}, 3, 23), ({'j'}, 3, 21), ({'w'}, 3, 11), ({'x'}, 3, 9), ({'u'}, 3, 8)]\n",
      "Guessing letter: t\n",
      "Got a Letter, t, # of tries remaining: 3. Word: _t__o.\n",
      "[({'p'}, 3, 128), ({'i'}, 3, 119), ({'u'}, 3, 92), ({'c'}, 3, 31), ({'m'}, 3, 16), ({'y'}, 3, 13), ({'l'}, 3, 10), ({'r'}, 3, 10), ({'d'}, 3, 9), ({'f'}, 3, 9), ({'n'}, 3, 9), ({'b'}, 3, 8), ({'g'}, 3, 8), ({'v'}, 3, 8), ({'k'}, 3, 4), ({'q'}, 3, 4), ({'h'}, 3, 3), ({'x'}, 3, 3), ({'j'}, 3, 2), ({'w'}, 3, 2), ({'z'}, 3, 1), ({'i'}, 2, 27596), ({'i'}, 2, 27596), ({'r'}, 2, 11607), ({'r'}, 2, 11607), ({'h'}, 2, 10336), ({'h'}, 2, 10336), ({'u'}, 2, 4243), ({'u'}, 2, 4243), ({'y'}, 2, 4137), ({'y'}, 2, 4137), ({'l'}, 2, 2137), ({'l'}, 2, 2137), ({'c'}, 2, 1246), ({'c'}, 2, 1246), ({'w'}, 2, 1188), ({'w'}, 2, 1188), ({'m'}, 2, 587), ({'m'}, 2, 587), ({'f'}, 2, 528), ({'f'}, 2, 528), ({'n'}, 2, 474), ({'n'}, 2, 474), ({'b'}, 2, 437), ({'b'}, 2, 437), ({'z'}, 2, 318), ({'z'}, 2, 318), ({'p'}, 2, 308), ({'p'}, 2, 308), ({'g'}, 2, 213), ({'g'}, 2, 213), ({'d'}, 2, 171), ({'d'}, 2, 171), ({'v'}, 2, 96), ({'v'}, 2, 96), ({'k'}, 2, 67), ({'k'}, 2, 67), ({'j'}, 2, 50), ({'j'}, 2, 50), ({'q'}, 2, 16), ({'q'}, 2, 16), ({'x'}, 2, 5), ({'x'}, 2, 5), ({'r'}, 3, 334), ({'n'}, 3, 289), ({'d'}, 3, 265), ({'l'}, 3, 253), ({'i'}, 3, 249), ({'c'}, 3, 227), ({'g'}, 3, 181), ({'m'}, 3, 109), ({'h'}, 3, 107), ({'b'}, 3, 82), ({'k'}, 3, 70), ({'p'}, 3, 49), ({'z'}, 3, 47), ({'v'}, 3, 47), ({'y'}, 3, 29), ({'f'}, 3, 23), ({'j'}, 3, 21), ({'w'}, 3, 11), ({'x'}, 3, 9), ({'u'}, 3, 8)]\n",
      "Guessing letter: i\n",
      "Got a Letter, i, # of tries remaining: 3. Word: _ti_o.\n",
      "[({'u'}, 4, 18), ({'p'}, 4, 10), ({'c'}, 4, 1), ({'d'}, 4, 1), ({'h'}, 4, 1), ({'j'}, 4, 1), ({'m'}, 4, 1), ({'n'}, 4, 1), ({'n'}, 5, 15), ({'c'}, 5, 14), ({'g'}, 5, 3), ({'b'}, 5, 2), ({'m'}, 5, 2), ({'v'}, 5, 1), ({'d'}, 5, 1), ({'p'}, 5, 1), ({'l'}, 5, 1), ({'r'}, 5, 1)]\n",
      "Guessing letter: n\n",
      "Incorrect guess n, # of tries remaining: 3. Word: _ti_o.\n",
      "[({'u'}, 4, 18), ({'p'}, 4, 10), ({'c'}, 4, 1), ({'d'}, 4, 1), ({'h'}, 4, 1), ({'j'}, 4, 1), ({'m'}, 4, 1), ({'c'}, 5, 14), ({'g'}, 5, 3), ({'b'}, 5, 2), ({'m'}, 5, 2), ({'v'}, 5, 1), ({'d'}, 5, 1), ({'p'}, 5, 1), ({'l'}, 5, 1), ({'r'}, 5, 1)]\n",
      "Guessing letter: c\n",
      "Incorrect guess c, # of tries remaining: 2. Word: _ti_o.\n",
      "[({'u'}, 4, 18), ({'p'}, 4, 10), ({'d'}, 4, 1), ({'h'}, 4, 1), ({'j'}, 4, 1), ({'m'}, 4, 1), ({'g'}, 5, 3), ({'b'}, 5, 2), ({'m'}, 5, 2), ({'v'}, 5, 1), ({'d'}, 5, 1), ({'p'}, 5, 1), ({'l'}, 5, 1), ({'r'}, 5, 1)]\n",
      "Guessing letter: p\n",
      "Got a Letter, p, # of tries remaining: 1. Word: pti_o.\n",
      "[({'l'}, 5, 6), ({'l'}, 5, 6), ({'l'}, 5, 5), ({'d'}, 5, 1), ({'f'}, 5, 1), ({'m'}, 5, 1), ({'g'}, 5, 3), ({'b'}, 5, 2), ({'m'}, 5, 2), ({'v'}, 5, 1), ({'d'}, 5, 1), ({'l'}, 5, 1), ({'r'}, 5, 1)]\n",
      "Guessing letter: l\n",
      "Success! the word was: ptilo\n"
     ]
    }
   ],
   "source": [
    "game.start_game()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like it is working but man does it get it wrong a lot..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "game.get_winstate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "game = MyHangman()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "on game 1 of 100\n",
      "win percentage: 0.000000\n",
      "on game 11 of 100\n",
      "win percentage: 63.636364\n",
      "on game 21 of 100\n",
      "win percentage: 71.428571\n",
      "on game 31 of 100\n",
      "win percentage: 67.741935\n",
      "on game 41 of 100\n",
      "win percentage: 68.292683\n",
      "on game 51 of 100\n",
      "win percentage: 64.705882\n",
      "on game 61 of 100\n",
      "win percentage: 63.934426\n",
      "on game 71 of 100\n",
      "win percentage: 61.971831\n",
      "on game 81 of 100\n",
      "win percentage: 60.493827\n",
      "on game 91 of 100\n",
      "win percentage: 60.439560\n",
      "\n",
      "win percentage:  61.0 %\n"
     ]
    }
   ],
   "source": [
    "wincount = 0\n",
    "N = 100\n",
    "for i in range(N):\n",
    "    if i % (N/10) == 0:\n",
    "        print(\"on game %i of %i\" % (i+1, N))\n",
    "        win_percent = 100*wincount/(i+1)\n",
    "        print(\"win percentage: %f\" % win_percent)\n",
    "    game.start_game(verbose=False)\n",
    "    wincount += game.get_winstate()\n",
    "print()\n",
    "print(\"win percentage: \", 100*wincount/N, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "win percentage:  64.0 %\n"
     ]
    }
   ],
   "source": [
    "print(\"win percentage: \", 100*wincount/N, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a significant improvement... hopefully... but it still isn't good enough in my opinion... I at least have parameters to tweak? It would be easier to mass tweak parameters if it was faster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Am I doing things wrong? I am still using the FULL dictionary to train the algorithm and test it. I need to test the algorithm on UNKNOWN words. I need to do a test/train split or load another data file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = open(\"words_250000_train.txt\",\"r\")\n",
    "full_dict = tf.read().splitlines()\n",
    "tf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = open(\"words_test.txt\",\"r\")\n",
    "test_dict = tf.read().splitlines()\n",
    "tf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "227300"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(full_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "170671"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3318021222117407"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(full_dict)/len(test_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
