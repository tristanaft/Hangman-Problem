{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# My hangman file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy\n",
    "import math\n",
    "import requests\n",
    "import random\n",
    "import string\n",
    "import secrets\n",
    "import time\n",
    "import re\n",
    "import collections\n",
    "from nltk import ngrams, FreqDist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = open(\"words_250000_train.txt\",\"r\")\n",
    "full_dict = tf.read().splitlines()\n",
    "tf.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tertianship'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.choice(full_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dict_common_letter_sorted = collections.Counter(\"\".join(full_dict)).most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('e', 233745)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_dict_common_letter_sorted[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, the main things I am revising are the n-gram matching and the evaluate guesses. What do they have to do?\n",
    "-Ok, I match the n-grams in a different way than other people do it, but I think my way is better.\n",
    "-I need to pad out the left and right for the n-gram for the generated word. The padding is to match for n-grams at the beginning and end I guess\n",
    "    -maybe I shouldnt do this...\n",
    "    -However, I have to discount stuff that is like (None a) or (a None) because those will cause issues with the \n",
    "-matching only can reccommend ONE letter. the way it is done in the other programs is forcing it into cases... but I can do it a different way.\n",
    "\n",
    "I am going to break the functions down here, fix them, and paste them back...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dictionary = full_dict\n",
    "\n",
    "#set up n-grams for current dictionary\n",
    "grams2 = []\n",
    "grams3 = []\n",
    "grams4 = []\n",
    "grams5 = []\n",
    "for word in full_dictionary:\n",
    "    #is the word clean? It should be...\n",
    "    #when I loaded the data it's fine...\n",
    "    #the API has be a bit nervous so lets just put this here\n",
    "    word = word.replace(\" \", \"\") #remove any padding that may mess with this\n",
    "\n",
    "    grams2.extend(list(ngrams(word, 2))) #if I pad left and match NONES with the length 2 n-grams, the program will start guessing first and last letters first...\n",
    "    grams3.extend(list(ngrams(word, 3, pad_left = True, pad_right = True)))\n",
    "    grams4.extend(list(ngrams(word, 4, pad_left = True, pad_right = True)))\n",
    "    grams5.extend(list(ngrams(word, 5, pad_left = True, pad_right = True)))\n",
    "\n",
    "#Ok, so now need the frequency distributions for these\n",
    "freq_dist_2 = FreqDist(grams2)\n",
    "freq_dist_3 = FreqDist(grams3)\n",
    "freq_dist_4 = FreqDist(grams4)\n",
    "freq_dist_5 = FreqDist(grams5)\n",
    "\n",
    "#need to actually extract the data from these distributions to use it\n",
    "freq_dist_2 = [(item, freq_dist_2.get(item)) for item in freq_dist_2]\n",
    "freq_dist_3 = [(item, freq_dist_3.get(item)) for item in freq_dist_3]\n",
    "freq_dist_4 = [(item, freq_dist_4.get(item)) for item in freq_dist_4]\n",
    "freq_dist_5 = [(item, freq_dist_5.get(item)) for item in freq_dist_5]\n",
    "\n",
    "words_by_length = {}\n",
    "min_word_length = 3 #shortest in the full_dict at least\n",
    "max_word_length = 40 #I guess this is pretty arbitrary\n",
    "\n",
    "for i in range(min_word_length, max_word_length):\n",
    "    words_by_length.update({i : []})\n",
    "\n",
    "#I do it in this kinda roundabout way because maybe there are words of 25 and 28 but no 27 or whatever\n",
    "#for word in self.full_dictionary:\n",
    "#    self.full_dictionary[len(word)].append(word)\n",
    "    \n",
    "\n",
    "#manually input a word and guess word...\n",
    "correct_word = \"apple\"\n",
    "word = \"_pp_e\"\n",
    "guess_list = [\"s\", \"p\", \"t\", \"e\"]\n",
    "#failed_letters = [\"s\", \"t\"]\n",
    "\n",
    "\n",
    "#def update_grams(self, word, guess_list):\n",
    "        #update ngrams to remove items associated with incorrect letters\n",
    "temp_word = word.replace(\"_\", \"\")\n",
    "incorrect_letters = set(guess_list) - set(temp_word)\n",
    "freq_dist_2 = [(item[0], item[1]) for item in freq_dist_2 if set(item[0]).isdisjoint(set(incorrect_letters))]\n",
    "freq_dist_3 = [(item[0], item[1]) for item in freq_dist_3 if set(item[0]).isdisjoint(set(incorrect_letters))]\n",
    "freq_dist_4 = [(item[0], item[1]) for item in freq_dist_4 if set(item[0]).isdisjoint(set(incorrect_letters))]\n",
    "freq_dist_5 = [(item[0], item[1]) for item in freq_dist_5 if set(item[0]).isdisjoint(set(incorrect_letters))]\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_potential_guesses(freq_N, input_word, guess_list):\n",
    "        #This takes as input a freq dist for n-grams and a word\n",
    "        #it outputs all the n-grams from freq dist that match along with the \n",
    "        potential_guesses = []\n",
    "        filtered_dist = []\n",
    "        if(freq_N == []):\n",
    "            dimension = 0\n",
    "        else:\n",
    "            dimension = len(freq_N[0][0])\n",
    "        word_ngrams = list(ngrams(input_word, dimension, pad_left = True, pad_right = True))\n",
    "        #print(dimension)\n",
    "        #There is an issue though, too much padding, so I will prune the word ngrams to prevent weird overmatching of NONEs\n",
    "        #print(item[0] for item in word_ngrams)\n",
    "        #print(word_ngrams)\n",
    "        word_ngrams = [item for item in word_ngrams if item.count(None) < 2]\n",
    "\n",
    "        for fe in freq_N:\n",
    "            #Ok..... so here is the idea...\n",
    "            #if the ngram in fe matches, then it must be a match \n",
    "            #to one of the n-gons of the target word with wildcards\n",
    "            fe_gram = fe[0]\n",
    "            occurrences = fe[1]\n",
    "            \n",
    "            #now, try to match it to one of the n-grams of the word...\n",
    "            matched_letters_count = 0 #you must match at least one letter to be considered\n",
    "\n",
    "            #how about this, I will potentially return guesses that are already in the guess_list\n",
    "            #and then filter them out in the next program when I go to evaluate the guesses.\n",
    "            #maybe also worry about the vowel thing there instead of here.\n",
    "\n",
    "            remove_set = set(guess_list)\n",
    "            remove_set.add(None)\n",
    "            \n",
    "            #print(\"I am inside the if statement\")\n",
    "            for word_gram in word_ngrams:\n",
    "                matched_letters_count = 0\n",
    "                for i in range(dimension):\n",
    "                    if(word_gram[i] != \"_\"): #there is a letter here, does the fe match?\n",
    "                        if(fe_gram[i] == word_gram[i]):\n",
    "                            matched_letters_count += 1\n",
    "                        else:\n",
    "                            #this happens if we have a direct contradiction, immediately reject this\n",
    "                            matched_letters_count = 0\n",
    "                            break\n",
    "                    #we don't have to check what the corresponding letter is if word_gram[i] is blank!\n",
    "                if(matched_letters_count == dimension - 1): #there should be n-1 matches and 1 guess\n",
    "                    potential_guesses.append((set(fe_gram) - remove_set, dimension,occurrences))\n",
    "                    #this is just for testing below vvvvvvvvv\n",
    "                    #potential_guesses.append((set(fe_gram) - remove_set, fe_gram, dimension,occurrences))\n",
    "\n",
    "                    #filtered_dist.append(fe)\n",
    "                    #print(set(fe_gram).issubset(guess_list))\n",
    "            \n",
    "        return potential_guesses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[({'r'}, ('r', 'e'), 2, 24800),\n",
       " ({'l'}, ('l', 'e'), 2, 22135),\n",
       " ({'n'}, ('n', 'e'), 2, 19584),\n",
       " ({'d'}, ('d', 'e'), 2, 13954),\n",
       " ({'h'}, ('h', 'e'), 2, 11707),\n",
       " ({'m'}, ('m', 'e'), 2, 11077),\n",
       " ({'v'}, ('v', 'e'), 2, 10593),\n",
       " (set(), ('p', 'e'), 2, 10209),\n",
       " (set(), ('p', 'e'), 2, 10209),\n",
       " ({'c'}, ('c', 'e'), 2, 9023),\n",
       " ({'h'}, ('p', 'h'), 2, 8865),\n",
       " ({'r'}, ('p', 'r'), 2, 8590),\n",
       " ({'i'}, ('i', 'e'), 2, 8301),\n",
       " ({'o'}, ('o', 'p'), 2, 8175),\n",
       " ({'g'}, ('g', 'e'), 2, 7326),\n",
       " ({'a'}, ('p', 'a'), 2, 7313),\n",
       " ({'o'}, ('p', 'o'), 2, 7255),\n",
       " ({'i'}, ('p', 'i'), 2, 6063),\n",
       " ({'a'}, ('a', 'p'), 2, 6038),\n",
       " ({'b'}, ('b', 'e'), 2, 5974),\n",
       " (set(), ('e', 'e'), 2, 5426),\n",
       " ({'k'}, ('k', 'e'), 2, 5188),\n",
       " (set(), ('e', 'p'), 2, 5034),\n",
       " ({'l'}, ('p', 'l'), 2, 4323),\n",
       " ({'i'}, ('i', 'p'), 2, 4121),\n",
       " ({'m'}, ('m', 'p'), 2, 3951),\n",
       " ({'z'}, ('z', 'e'), 2, 3531),\n",
       " ({'a'}, ('a', 'e'), 2, 3350),\n",
       " ({'f'}, ('f', 'e'), 2, 3328),\n",
       " ({'w'}, ('w', 'e'), 2, 3228),\n",
       " ({'u'}, ('u', 'p'), 2, 2942),\n",
       " (set(), ('p', 'p'), 2, 2260),\n",
       " (set(), ('p', 'p'), 2, 2260),\n",
       " ({'u'}, ('u', 'e'), 2, 2259),\n",
       " ({'u'}, ('p', 'u'), 2, 2223),\n",
       " ({'y'}, ('y', 'p'), 2, 2029),\n",
       " ({'r'}, ('r', 'p'), 2, 2021),\n",
       " ({'o'}, ('o', 'e'), 2, 1715),\n",
       " ({'n'}, ('n', 'p'), 2, 1403),\n",
       " ({'y'}, ('y', 'e'), 2, 1380),\n",
       " ({'y'}, ('p', 'y'), 2, 970),\n",
       " ({'l'}, ('l', 'p'), 2, 950),\n",
       " ({'j'}, ('j', 'e'), 2, 735),\n",
       " ({'x'}, ('x', 'e'), 2, 638),\n",
       " ({'x'}, ('x', 'p'), 2, 540),\n",
       " ({'n'}, ('p', 'n'), 2, 304),\n",
       " ({'d'}, ('d', 'p'), 2, 190),\n",
       " ({'b'}, ('p', 'b'), 2, 145),\n",
       " ({'m'}, ('p', 'm'), 2, 141),\n",
       " ({'h'}, ('h', 'p'), 2, 140),\n",
       " ({'w'}, ('p', 'w'), 2, 124),\n",
       " ({'f'}, ('p', 'f'), 2, 123),\n",
       " ({'b'}, ('b', 'p'), 2, 122),\n",
       " ({'c'}, ('p', 'c'), 2, 122),\n",
       " ({'f'}, ('f', 'p'), 2, 116),\n",
       " ({'k'}, ('k', 'p'), 2, 111),\n",
       " ({'d'}, ('p', 'd'), 2, 84),\n",
       " ({'g'}, ('g', 'p'), 2, 81),\n",
       " ({'w'}, ('w', 'p'), 2, 73),\n",
       " ({'g'}, ('p', 'g'), 2, 56),\n",
       " ({'c'}, ('c', 'p'), 2, 51),\n",
       " ({'k'}, ('p', 'k'), 2, 45),\n",
       " ({'v'}, ('p', 'v'), 2, 17),\n",
       " ({'j'}, ('p', 'j'), 2, 14),\n",
       " ({'z'}, ('z', 'p'), 2, 12),\n",
       " ({'v'}, ('v', 'p'), 2, 7),\n",
       " ({'q'}, ('q', 'e'), 2, 5),\n",
       " ({'j'}, ('j', 'p'), 2, 3),\n",
       " ({'x'}, ('p', 'x'), 2, 2),\n",
       " ({'z'}, ('p', 'z'), 2, 1),\n",
       " ({'q'}, ('q', 'p'), 2, 1),\n",
       " ({'q'}, ('p', 'q'), 2, 1)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_potential_guesses(freq_dist_2, word, guess_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are issues with the padding... I need to prune everything that has at least 2 NONEs. That includes the `freq_n` and the ngrams of the word...\n",
    "Maybe I just need to prune the ones from the word?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[({'a'}, (None, 'a', 'p', 'p'), 4, 275),\n",
       " ({'l'}, ('p', 'l', 'e', None), 4, 135),\n",
       " ({'l'}, ('p', 'p', 'l', 'e'), 4, 122),\n",
       " ({'r'}, ('p', 'p', 'r', 'e'), 4, 119),\n",
       " ({'i'}, ('p', 'p', 'i', 'e'), 4, 66),\n",
       " ({'o'}, (None, 'o', 'p', 'p'), 4, 56),\n",
       " ({'i'}, ('p', 'i', 'e', None), 4, 42),\n",
       " ({'u'}, (None, 'u', 'p', 'p'), 4, 32),\n",
       " ({'h'}, ('p', 'h', 'e', None), 4, 26),\n",
       " (set(), ('p', 'p', 'e', None), 4, 26),\n",
       " (set(), ('p', 'e', 'e', None), 4, 25),\n",
       " (set(), (None, None, 'p', 'p'), 4, 10),\n",
       " (set(), ('p', 'p', 'e', 'e'), 4, 5),\n",
       " ({'n'}, ('p', 'n', 'e', None), 4, 4),\n",
       " ({'a'}, ('p', 'a', 'e', None), 4, 4),\n",
       " ({'r'}, ('p', 'r', 'e', None), 4, 4),\n",
       " (set(), (None, 'e', 'p', 'p'), 4, 4),\n",
       " ({'o'}, ('p', 'o', 'e', None), 4, 3),\n",
       " ({'u'}, ('p', 'u', 'e', None), 4, 3),\n",
       " ({'a'}, ('p', 'p', 'a', 'e'), 4, 2),\n",
       " ({'n'}, ('p', 'p', 'n', 'e'), 4, 2),\n",
       " ({'c'}, ('p', 'c', 'e', None), 4, 2),\n",
       " ({'d'}, (None, 'd', 'p', 'p'), 4, 1),\n",
       " ({'l'}, (None, 'l', 'p', 'p'), 4, 1),\n",
       " ({'m'}, (None, 'm', 'p', 'p'), 4, 1),\n",
       " ({'n'}, (None, 'n', 'p', 'p'), 4, 1),\n",
       " ({'d'}, ('p', 'd', 'e', None), 4, 1),\n",
       " (set(), (None, 'p', 'p', 'p'), 4, 1),\n",
       " ({'y'}, ('p', 'y', 'e', None), 4, 1),\n",
       " ({'h'}, ('p', 'p', 'h', 'e'), 4, 1),\n",
       " ({'j'}, ('p', 'j', 'e', None), 4, 1),\n",
       " ({'k'}, ('p', 'k', 'e', None), 4, 1)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_potential_guesses(freq_dist_4, word, guess_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[({'l'}, ('p', 'p', 'l', 'e', None), 5, 37),\n",
       " ({'i'}, ('p', 'p', 'i', 'e', None), 5, 13),\n",
       " (set(), ('p', 'p', 'e', 'e', None), 5, 2),\n",
       " ({'a'}, ('p', 'p', 'a', 'e', None), 5, 1)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_potential_guesses(freq_dist_5, word, guess_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_2_guesses = find_potential_guesses(freq_dist_2, word, guess_list)\n",
    "freq_3_guesses = find_potential_guesses(freq_dist_3, word, guess_list)\n",
    "freq_4_guesses = find_potential_guesses(freq_dist_4, word, guess_list)\n",
    "freq_5_guesses = find_potential_guesses(freq_dist_5, word, guess_list)\n",
    "all_guesses = freq_2_guesses + freq_3_guesses + freq_4_guesses + freq_5_guesses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[({'r'}, 2, 24800), ({'l'}, 2, 22135), ({'n'}, 2, 19584), ({'d'}, 2, 13954), ({'h'}, 2, 11707), ({'m'}, 2, 11077), ({'v'}, 2, 10593), (set(), 2, 10209), (set(), 2, 10209), ({'c'}, 2, 9023)]\n"
     ]
    }
   ],
   "source": [
    "print(all_guesses[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[({'l'}, 5, 37), ({'i'}, 5, 13), ({'a'}, 5, 1), ({'a'}, 4, 275), ({'l'}, 4, 135), ({'l'}, 4, 122), ({'r'}, 4, 119), ({'i'}, 4, 66), ({'o'}, 4, 56), ({'i'}, 4, 42)]\n"
     ]
    }
   ],
   "source": [
    "filtered_guesses = [item for item in all_guesses if item[0] != set()] #this filters out all the guesses with no letters in them\n",
    "sorted_guesses = sorted(filtered_guesses, key = lambda tup: tup[1], reverse = True)\n",
    "print(sorted_guesses[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_potential_guesses(potential_guesses):\n",
    "        #each potential guess is in the form:\n",
    "        #({letters}, dimension from ngram, matched letters count, occurrences of pattern in dict)\n",
    "\n",
    "        #So, which do we pick:\n",
    "        #prioritize ngram length first\n",
    "        #then pick based on most frequent letter\n",
    "        #I guess how many letters match isnt as important...\n",
    "        #I have read that vowel ratio may make a difference... maybe implement later\n",
    "\n",
    "        sorted_guesses = sorted(potential_guesses, key = lambda tup: tup[1], reverse = True)\n",
    "        if(sorted_guesses != []):\n",
    "            max_dim = sorted_guesses[0][1]\n",
    "            #print(max_dim)\n",
    "            max_dim_guesses = [x for x in sorted_guesses if x[1] == max_dim]\n",
    "            max_dim_guesses.sort(key = lambda tup: tup[2], reverse = True)\n",
    "\n",
    "            #print(max_dim_guesses[0])\n",
    "            max_dim_guesses[0][0]\n",
    "            max_guess = max_dim_guesses[0]\n",
    "            #print(max_guess)\n",
    "            max_guess = list(max_guess)[0] #this is to get the actual string instead of a set\n",
    "            if len(max_guess) > 0:\n",
    "                max_guess = list(max_guess)[0]\n",
    "            \n",
    "            \n",
    "            return max_guess #this is a set in general\n",
    "        else:\n",
    "            return \"!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'l'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_potential_guesses(all_guesses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok... now just need a program to sort through all of the different n-grams and pick the best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import ngrams, FreqDist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyHangman(object):\n",
    "    def __init__(self, access_token=None, session=None, timeout=None):\n",
    "        self.guessed_letters = []\n",
    "        #should include a self word and self correct word\n",
    "        self.word = \"\"\n",
    "        self.correct_word = \"\"\n",
    "        full_dictionary_location = \"words_250000_train.txt\"\n",
    "        self.full_dictionary = self.build_dictionary(full_dictionary_location)        \n",
    "        self.full_dictionary_common_letter_sorted = collections.Counter(\"\".join(self.full_dictionary)).most_common()\n",
    "        self.current_dictionary = []\n",
    "        self.alphabet = list(string.ascii_lowercase)\n",
    "        self.vowels = list([\"a\", \"e\", \"i\", \"o\", \"u\"])\n",
    "        self.guess_list = []\n",
    "        self.has_won = False\n",
    "        self.init_grams()\n",
    "        #self.init_grams()\n",
    "\n",
    "    def init_grams(self):\n",
    "        #set up n-grams for current dictionary\n",
    "        grams2 = []\n",
    "        grams3 = []\n",
    "        grams4 = []\n",
    "        grams5 = []\n",
    "        for word in self.full_dictionary:\n",
    "            #is the word clean? It should be...\n",
    "            #when I loaded the data it's fine...\n",
    "            #the API has be a bit nervous so lets just put this here\n",
    "            word = word.replace(\" \", \"\") #remove any padding that may mess with this\n",
    "\n",
    "            grams2.extend(list(ngrams(word, 2)))# padding on 2 messes up the guesses.\n",
    "            grams3.extend(list(ngrams(word, 3, pad_left = True, pad_right = True)))\n",
    "            grams4.extend(list(ngrams(word, 4, pad_left = True, pad_right = True)))\n",
    "            grams5.extend(list(ngrams(word, 5, pad_left = True, pad_right = True)))\n",
    "        \n",
    "        #Ok, so now need the frequency distributions for these\n",
    "        freq_dist_2 = FreqDist(grams2)\n",
    "        freq_dist_3 = FreqDist(grams3)\n",
    "        freq_dist_4 = FreqDist(grams4)\n",
    "        freq_dist_5 = FreqDist(grams5)\n",
    "\n",
    "        #need to actually extract the data from these distributions to use it\n",
    "        self.freq_dist_2 = [(item, freq_dist_2.get(item)) for item in freq_dist_2]\n",
    "        self.freq_dist_3 = [(item, freq_dist_3.get(item)) for item in freq_dist_3]\n",
    "        self.freq_dist_4 = [(item, freq_dist_4.get(item)) for item in freq_dist_4]\n",
    "        self.freq_dist_5 = [(item, freq_dist_5.get(item)) for item in freq_dist_5]\n",
    "\n",
    "        self.words_by_length = {}\n",
    "        min_word_length = 3 #shortest in the full_dict at least\n",
    "        max_word_length = 40 #I guess this is pretty arbitrary\n",
    "\n",
    "        for i in range(min_word_length, max_word_length):\n",
    "            self.words_by_length.update({i : []})\n",
    "\n",
    "        #I do it in this kinda roundabout way because maybe there are words of 25 and 28 but no 27 or whatever\n",
    "        #for word in self.full_dictionary:\n",
    "        #    self.full_dictionary[len(word)].append(word)\n",
    "        \n",
    "            \n",
    "        \n",
    "    def generate_correct_word(self):\n",
    "        self.correct_word = random.choice(self.full_dictionary)\n",
    "\n",
    "\n",
    "    #I think this is an easier way to apply ngrams... I don't really know as much about the subject\n",
    "        #so there is an equal or greater likelihood that this is completely wrong\n",
    "    def find_potential_guesses(self, freq_N, input_word, guess_list):\n",
    "        #This takes as input a freq dist for n-grams and a word\n",
    "        #it outputs all the n-grams from freq dist that match along with the \n",
    "        potential_guesses = []\n",
    "        filtered_dist = []\n",
    "        if(freq_N == []):\n",
    "            dimension = 0\n",
    "        else:\n",
    "            dimension = len(freq_N[0][0])\n",
    "        word_ngrams = list(ngrams(input_word, dimension, pad_left = True, pad_right = True))\n",
    "        #print(dimension)\n",
    "        #There is an issue though, too much padding, so I will prune the word ngrams to prevent weird overmatching of NONEs\n",
    "        #print(item[0] for item in word_ngrams)\n",
    "        #print(word_ngrams)\n",
    "        word_ngrams = [item for item in word_ngrams if item.count(None) < 2]\n",
    "        #print(guess_list)\n",
    "        remove_set = set(guess_list)\n",
    "        remove_set.add(None)\n",
    "\n",
    "        for fe in freq_N:\n",
    "            #Ok..... so here is the idea...\n",
    "            #if the ngram in fe matches, then it must be a match \n",
    "            #to one of the n-gons of the target word with wildcards\n",
    "            fe_gram = fe[0]\n",
    "            occurrences = fe[1]\n",
    "            \n",
    "            #now, try to match it to one of the n-grams of the word...\n",
    "            matched_letters_count = 0 #you must match at least one letter to be considered\n",
    "\n",
    "            #how about this, I will potentially return guesses that are already in the guess_list\n",
    "            #and then filter them out in the next program when I go to evaluate the guesses.\n",
    "            #maybe also worry about the vowel thing there instead of here.\n",
    "            \n",
    "            #print(\"I am inside the if statement\")\n",
    "            for word_gram in word_ngrams:\n",
    "                matched_letters_count = 0\n",
    "                for i in range(dimension):\n",
    "                    if(word_gram[i] != \"_\"): #there is a letter here, does the fe match?\n",
    "                        if(fe_gram[i] == word_gram[i]):\n",
    "                            matched_letters_count += 1\n",
    "                        else:\n",
    "                            #this happens if we have a direct contradiction, immediately reject this\n",
    "                            matched_letters_count = 0\n",
    "                            break\n",
    "                    #we don't have to check what the corresponding letter is if word_gram[i] is blank!\n",
    "                if(matched_letters_count == dimension - 1): #there should be n-1 matches and 1 guess\n",
    "                    potential_guesses.append((set(fe_gram) - remove_set, dimension,occurrences))\n",
    "                    #this is just for testing below vvvvvvvvv\n",
    "                    #potential_guesses.append((set(fe_gram) - remove_set, fe_gram, dimension,occurrences))\n",
    "\n",
    "                    #filtered_dist.append(fe)\n",
    "                    #print(set(fe_gram).issubset(guess_list))\n",
    "            \n",
    "        return potential_guesses\n",
    "        \n",
    "    def evaluate_potential_guesses(self, potential_guesses):\n",
    "        #each potential guess is in the form:\n",
    "        #({letters}, dimension from ngram, matched letters count, occurrences of pattern in dict)\n",
    "\n",
    "        #So, which do we pick:\n",
    "        #prioritize ngram length first\n",
    "        #then pick based on most frequent letter\n",
    "        #I guess how many letters match isnt as important...\n",
    "        #I have read that vowel ratio may make a difference... maybe implement later\n",
    "\n",
    "        #ok, need to prune stuff... not pruning enough.\n",
    "\n",
    "        filtered_guesses = [item for item in potential_guesses if item[0] != set()] #this filters out all the guesses with no letters in them\n",
    "        sorted_guesses = sorted(filtered_guesses, key = lambda tup: tup[1], reverse = True)\n",
    "\n",
    "        #sorted_guesses = sorted(potential_guesses, key = lambda tup: tup[1], reverse = True)\n",
    "        if(sorted_guesses != []):\n",
    "            max_dim = sorted_guesses[0][1]\n",
    "            #print(max_dim)\n",
    "            max_dim_guesses = [x for x in sorted_guesses if x[1] == max_dim]\n",
    "            max_dim_guesses.sort(key = lambda tup: tup[2], reverse = True)\n",
    "\n",
    "            #print(max_dim_guesses[0])\n",
    "            max_dim_guesses[0][0]\n",
    "            max_guess = max_dim_guesses[0]\n",
    "            #print(max_guess)\n",
    "            max_guess = list(max_guess)[0] #this is to get the actual string instead of a set\n",
    "            if len(max_guess) > 0:\n",
    "                max_guess = list(max_guess)[0]\n",
    "            \n",
    "            \n",
    "            return max_guess #this is a set in general\n",
    "        else:\n",
    "            return \"!\"\n",
    "    \n",
    "    def update_grams(self, freq_dist_list ,word, guess_list):\n",
    "        #freq_grams is in the form [freq_dist_2, freq_dist_3, freq_dist_4, freq_dist_5]\n",
    "\n",
    "        #update ngrams to remove items associated with incorrect letters\n",
    "        word = word.replace(\"_\", \"\")\n",
    "        incorrect_letters = set(guess_list) - set(word)\n",
    "        for freq_dist in freq_dist_list:\n",
    "            freq_dist = [(item[0], item[1]) for item in freq_dist if set(item[0]).isdisjoint(set(incorrect_letters))]\n",
    "        #freq_dist_2 = [(item[0], item[1]) for item in freq_dist_2 if set(item[0]).isdisjoint(set(incorrect_letters))]\n",
    "        #freq_dist_3 = [(item[0], item[1]) for item in freq_dist_3 if set(item[0]).isdisjoint(set(incorrect_letters))]\n",
    "        #freq_dist_4 = [(item[0], item[1]) for item in freq_dist_4 if set(item[0]).isdisjoint(set(incorrect_letters))]\n",
    "        #freq_dist_5 = [(item[0], item[1]) for item in freq_dist_5 if set(item[0]).isdisjoint(set(incorrect_letters))]\n",
    "        return freq_dist_list\n",
    "\n",
    "\n",
    "\n",
    "    def guess(self, word, freq_dist_list): # word input example: \"_ p p _ e \"\n",
    "        ###############################################\n",
    "        # Replace with your own \"guess\" function here #\n",
    "        ###############################################\n",
    "\n",
    "        # clean the word so that we strip away the space characters\n",
    "        # replace \"_\" with \".\" as \".\" indicates any character in regular expressions\n",
    "        # The extra space characters must be coming from the website...\n",
    "        clean_word = word.replace(\" \", \"\") #I am putting this here in case I forget later to remove the space stuff when I paste this into the solution\n",
    "        #clean_word = word.replace(\"_\",\".\") #I am using underscores\n",
    "\n",
    "        # find length of passed word\n",
    "        len_word = len(clean_word)\n",
    "        \n",
    "        # grab current dictionary of possible words from self object, initialize new possible words dictionary to empty\n",
    "        current_dictionary = self.current_dictionary\n",
    "        new_dictionary = []\n",
    "        #print(current_dictionary[0])\n",
    "        \n",
    "        # iterate through all of the words in the old plausible dictionary\n",
    "        for dict_word in current_dictionary:\n",
    "            # continue if the word is not of the appropriate length\n",
    "            if len(dict_word) != len_word:\n",
    "                continue\n",
    "                \n",
    "            # if dictionary word is a possible match then add it to the current dictionary\n",
    "            if re.match(clean_word,dict_word):\n",
    "                new_dictionary.append(dict_word)\n",
    "        \n",
    "        # overwrite old possible words dictionary with updated version\n",
    "        self.current_dictionary = new_dictionary\n",
    "        \n",
    "        \n",
    "        # count occurrence of all characters in possible word matches\n",
    "        full_dict_string = \"\".join(new_dictionary)\n",
    "        \n",
    "        c = collections.Counter(full_dict_string)\n",
    "        sorted_letter_count = c.most_common()\n",
    "        #print(sorted_letter_count)                \n",
    "        \n",
    "        guess_letter = '!'\n",
    "\n",
    "        #print(self.freq_dist_2[0:10])\n",
    "        #print(self.freq_dist_3[0:10])\n",
    "        #print(self.freq_dist_4[0:10])\n",
    "        #print(self.freq_dist_5[0:10])\n",
    "        #print(self.guessed_letters)\n",
    "        #print(len(self.guessed_letters))\n",
    "\n",
    "        #freq_2_guesses = self.find_potential_guesses(self.freq_dist_2, word, self.guessed_letters)\n",
    "        #freq_3_guesses = self.find_potential_guesses(self.freq_dist_3, word, self.guessed_letters)\n",
    "        #freq_4_guesses = self.find_potential_guesses(self.freq_dist_4, word, self.guessed_letters)\n",
    "        #freq_5_guesses = self.find_potential_guesses(self.freq_dist_5, word, self.guessed_letters)\n",
    "        #print(\"freq 2 guesses \",freq_2_guesses[0:10])\n",
    "        #print(freq_3_guesses[0:10])\n",
    "        #print(freq_4_guesses[0:10])\n",
    "        #print(freq_5_guesses[0:10])\n",
    "        #print()\n",
    "\n",
    "        all_guesses = []\n",
    "        for fd in freq_dist_list:\n",
    "            fd_guesses = self.find_potential_guesses(fd, word, self.guessed_letters)\n",
    "            all_guesses += fd_guesses\n",
    "\n",
    "        \n",
    "\n",
    "        #all_guesses = freq_2_guesses + freq_3_guesses + freq_4_guesses + freq_5_guesses\n",
    "        max_guess = self.evaluate_potential_guesses(all_guesses)\n",
    "        \n",
    "        \n",
    "        # return most frequently occurring letter in all possible words that hasn't been guessed yet\n",
    "        for letter,instance_count in sorted_letter_count:\n",
    "            if letter not in self.guessed_letters:\n",
    "                guess_letter = letter\n",
    "                break\n",
    "            \n",
    "        # if no word matches in training dictionary, default back to ordering of full dictionary\n",
    "        if guess_letter == '!':\n",
    "            sorted_letter_count = self.full_dictionary_common_letter_sorted\n",
    "            for letter,instance_count in sorted_letter_count:\n",
    "                if letter not in self.guessed_letters:\n",
    "                    guess_letter = letter\n",
    "                    break            \n",
    "        \n",
    "        #print(sorted_letter_count)  \n",
    "        #print(max_guess)\n",
    "        #print(sorted_letter_count(max_guess[0])) \n",
    "        if(max_guess != \"!\"):\n",
    "            #max_guess is in a form like {\"a\", \"b\"} or something\n",
    "            #let's pick the most likely letter from among these\n",
    "            guess_letter = max_guess\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "        return guess_letter\n",
    "\n",
    "    ##########################################################\n",
    "    # You'll likely not need to modify any of the code below #\n",
    "    ##########################################################\n",
    "    \n",
    "    def build_dictionary(self, dictionary_file_location):\n",
    "        text_file = open(dictionary_file_location,\"r\")\n",
    "        full_dictionary = text_file.read().splitlines()\n",
    "        text_file.close()\n",
    "        return full_dictionary\n",
    "\n",
    "    #what do I need to replace the responses?\n",
    "    #get a word\n",
    "    #get remaining tries\n",
    "    #print number of tries remaining\n",
    "    #go through the process of resolving a guess\n",
    "    #\n",
    "\n",
    "    def handle_guess(self, guessLetter, currentWord, ans):\n",
    "        #I have to convert the strings to lists, find indices of the letter (if present) and then smush the lists back into strings and spit it out\n",
    "        indices = [i for i, x in enumerate(list(ans)) if x == guessLetter]\n",
    "        wordList = list(currentWord)\n",
    "        for i in indices:\n",
    "            wordList[i] = guessLetter #now I replace the occurrences of the letter\n",
    "        word = \"\".join(wordList)\n",
    "        return word\n",
    "\n",
    "    def get_winstate(self):\n",
    "        return self.has_won\n",
    "        \n",
    "                \n",
    "    def start_game(self, practice=True, verbose=True):\n",
    "        # reset guessed letters to empty set and current plausible dictionary to the full dictionary\n",
    "        self.guessed_letters = []\n",
    "        self.current_dictionary = self.full_dictionary\n",
    "        #self.init_grams()\n",
    "        freq_dist_list = [self.freq_dist_2, self.freq_dist_3, self.freq_dist_4, self.freq_dist_5]\n",
    "        self.has_won = False\n",
    "        #pick a word from the dictionary at random.\n",
    "        #correctWord = random.choice(self.full_dictionary) #this is the initial word, but need to update it based on guesses\n",
    "        self.generate_correct_word()\n",
    "        word = \"_\" * len(self.correct_word) #I should make this a member of self right?\n",
    "\n",
    "        tries_remains = 6 #I think this needs to just be a magic number?\n",
    "        if verbose:\n",
    "            print(\"Successfully start a new game! # of tries remaining: {0}. Word: {1}.\".format(tries_remains, word))\n",
    "        while tries_remains >0:\n",
    "            #tries_remains -=1 tries remains decreases after WRONG answer\n",
    "\n",
    "            #get guessed letter\n",
    "            guess_letter = self.guess(word, freq_dist_list)\n",
    "\n",
    "            #append guessed letter to guessed letters field in hangman object\n",
    "            self.guessed_letters.append(guess_letter)\n",
    "\n",
    "            freq_dist_list = self.update_grams(freq_dist_list, word, self.guess_list)\n",
    "            if verbose:\n",
    "                print(\"Guessing letter: {0}\".format(guess_letter))\n",
    "\n",
    "            #apply guessed letter to the word\n",
    "            new_word = self.handle_guess(guess_letter, word, self.correct_word) \n",
    "\n",
    "            #check if we have the word\n",
    "            if new_word == self.correct_word:\n",
    "                word = new_word\n",
    "                if verbose:\n",
    "                    print(\"Success! the word was: %s\" % word)\n",
    "                self.has_won = True\n",
    "                break\n",
    "            \n",
    "            if new_word == word:\n",
    "                #this means that we did not get a correct guess\n",
    "                #decrease number of tries\n",
    "                if verbose:\n",
    "                    print(\"Incorrect guess {0}, # of tries remaining: {1}. Word: {2}.\".format(guess_letter,tries_remains, word))\n",
    "                tries_remains -=1\n",
    "            else:\n",
    "                #We have a correct letter guessed, but not the complete word\n",
    "                #don't decrement tries_remains\n",
    "                word = new_word\n",
    "                if verbose:\n",
    "                    print(\"Got a Letter, {0}, # of tries remaining: {1}. Word: {2}.\".format(guess_letter,tries_remains, word))\n",
    "        if tries_remains == 0:\n",
    "            if verbose:\n",
    "                print(\"You Lose, the answer was: %s\" % self.correct_word)\n",
    "                \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully start a new game! # of tries remaining: 6. Word: _____.\n",
      "Guessing letter: e\n",
      "Incorrect guess e, # of tries remaining: 6. Word: _____.\n",
      "Guessing letter: i\n",
      "Incorrect guess i, # of tries remaining: 5. Word: _____.\n",
      "Guessing letter: a\n",
      "Got a Letter, a, # of tries remaining: 4. Word: _a_a_.\n",
      "Guessing letter: l\n",
      "Incorrect guess l, # of tries remaining: 4. Word: _a_a_.\n",
      "Guessing letter: n\n",
      "Incorrect guess n, # of tries remaining: 3. Word: _a_a_.\n",
      "Guessing letter: c\n",
      "Got a Letter, c, # of tries remaining: 2. Word: _aca_.\n",
      "Guessing letter: m\n",
      "Got a Letter, m, # of tries remaining: 2. Word: maca_.\n",
      "Guessing letter: r\n",
      "Incorrect guess r, # of tries remaining: 2. Word: maca_.\n",
      "Guessing letter: s\n",
      "Incorrect guess s, # of tries remaining: 1. Word: maca_.\n",
      "You Lose, the answer was: macap\n"
     ]
    }
   ],
   "source": [
    "game = MyHangman()\n",
    "game.start_game()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like it is working but man does it get it wrong a lot..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "game.get_winstate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "game = MyHangman()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "on game 1 of 100\n",
      "win percentage: 0.000000\n",
      "on game 11 of 100\n",
      "win percentage: 63.636364\n",
      "on game 21 of 100\n",
      "win percentage: 47.619048\n",
      "on game 31 of 100\n",
      "win percentage: 48.387097\n",
      "on game 41 of 100\n",
      "win percentage: 53.658537\n",
      "on game 51 of 100\n",
      "win percentage: 50.980392\n",
      "on game 61 of 100\n",
      "win percentage: 54.098361\n",
      "on game 71 of 100\n",
      "win percentage: 50.704225\n",
      "on game 81 of 100\n",
      "win percentage: 50.617284\n",
      "on game 91 of 100\n",
      "win percentage: 49.450549\n",
      "\n",
      "win percentage:  49.0 %\n"
     ]
    }
   ],
   "source": [
    "wincount = 0\n",
    "N = 100\n",
    "for i in range(N):\n",
    "    if i % (N/10) == 0:\n",
    "        print(\"on game %i of %i\" % (i+1, N))\n",
    "        win_percent = 100*wincount/(i+1)\n",
    "        print(\"win percentage: %f\" % win_percent)\n",
    "    game.start_game(verbose=False)\n",
    "    wincount += game.get_winstate()\n",
    "print()\n",
    "print(\"win percentage: \", 100*wincount/N, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "win percentage:  50.0 %\n"
     ]
    }
   ],
   "source": [
    "print(\"win percentage: \", 100*wincount/N, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is SUPER slow... the main thing I think takes forever is just setting up the freq dists... but it should be the same as in the original... so why does this take so much longer?\n",
    "\n",
    "Maybe I can just save the freq dists, and then when I actually do the program make copies that I prune instead of redoing them EVERY TIME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It takes about 15 seconds per game... which SUCKS REALLY BAD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well... that is pretty disappointing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
